{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a840d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'cosine_similarity_content.npy' successfully.\n",
      "Cosine similarity matrix shape: (9742, 9742)\n",
      "\n",
      "--- Training Collaborative Filtering Model ---\n",
      "\n",
      "--- Testing Collaborative Recommendations for User 1 ---\n",
      "     title_clean  predicted_collaborative_score  \\\n",
      "370    Firm, The                       2.124894   \n",
      "1321    Rain Man                       1.982790   \n",
      "3508     Ice Age                       1.965882   \n",
      "371   Free Willy                       1.834887   \n",
      "12        Casino                       1.725971   \n",
      "\n",
      "                               genres_str  \n",
      "370                        Drama Thriller  \n",
      "1321                                Drama  \n",
      "3508  Adventure Animation Children Comedy  \n",
      "371              Adventure Children Drama  \n",
      "12                            Crime Drama  \n",
      "\n",
      "--- Testing Hybrid Recommendations for User 1 ---\n",
      "User 1 has 200 valid liked movie indices: [0, 2, 5, 43, 46, 89, 97, 124, 130, 136, 184, 197, 201, 224, 291, 307, 314, 320, 325, 384, 398, 418, 461, 476, 484, 485, 508, 509, 510, 513, 520, 551, 592, 632, 701, 705, 720, 723, 734, 781, 782, 783, 786, 788, 789, 797, 801, 810, 815, 820, 828, 829, 831, 836, 856, 863, 898, 899, 900, 907, 909, 911, 914, 915, 921, 923, 925, 927, 939, 955, 964, 969, 974, 977, 981, 990, 996, 1036, 1126, 1146, 1154, 1171, 1181, 1190, 1218, 1220, 1224, 1298, 1319, 1326, 1332, 1333, 1401, 1407, 1431, 1444, 1475, 1480, 1487, 1493, 1503, 1505, 1516, 1517, 1522, 1526, 1543, 1553, 1557, 1559, 1562, 1567, 1576, 1577, 1595, 1597, 1599, 1601, 1617, 1628, 1644, 1687, 1691, 1704, 1734, 1755, 1768, 1788, 1796, 1806, 1826, 1842, 1850, 1858, 1866, 1874, 1883, 1905, 1917, 1939, 1946, 1957, 1971, 1979, 1986, 1987, 1990, 1991, 1994, 2020, 2028, 2038, 2077, 2103, 2126, 2145, 2157, 2182, 2193, 2216, 2218, 2219, 2220, 2226, 2248, 2250, 2254, 2256, 2259, 2286, 2287, 2302, 2303, 2310, 2372, 2388, 2440, 2460, 2526, 2571, 2572, 2573, 2579, 2581, 2603, 2608, 2636, 2674, 2696, 2713, 2733, 2764, 2765, 2788, 2798, 2802, 2836, 2847, 2991, 3673]\n",
      "                      title_clean  hybrid_score  \\\n",
      "0                             NaN      0.500000   \n",
      "1  Dragonheart 2: A New Beginning      0.500000   \n",
      "2                             NaN      0.414922   \n",
      "3                             NaN      0.404800   \n",
      "4         The Great Train Robbery      0.358912   \n",
      "\n",
      "                                       genres_str  \n",
      "0                                             NaN  \n",
      "1  Action Adventure Comedy Drama Fantasy Thriller  \n",
      "2                                             NaN  \n",
      "3                                             NaN  \n",
      "4             Action Adventure Comedy Crime Drama  \n",
      "\n",
      "Truncated SVD model saved to '../models/truncated_svd_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "# Load datasets\n",
    "movies_df = pd.read_csv('../data/movies_processed.csv')\n",
    "ratings_df = pd.read_csv('../data/ratings.csv')\n",
    "\n",
    "# Load content-based similarity matrix\n",
    "try:\n",
    "    cosine_sim_content = np.load('../data/cosine_similarity_content.npy')\n",
    "    print(\"Loaded 'cosine_similarity_content.npy' successfully.\")\n",
    "    print(f\"Cosine similarity matrix shape: {cosine_sim_content.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'cosine_similarity_content.npy' not found in '../Data/'. Please ensure it is generated from the content-based module.\")\n",
    "    raise\n",
    "\n",
    "# Verify cosine_sim_content aligns with movies_df\n",
    "if cosine_sim_content.shape[0] != len(movies_df):\n",
    "    print(f\"Warning: cosine_sim_content has {cosine_sim_content.shape[0]} rows, but movies_df has {len(movies_df)} rows.\")\n",
    "    raise ValueError(\"Mismatch between cosine_sim_content and movies_df.\")\n",
    "\n",
    "# Recreate indices mapping (movieId to DataFrame index for consistency)\n",
    "indices = pd.Series(movies_df.index, index=movies_df['movieId']).drop_duplicates()\n",
    "\n",
    "# --- Collaborative Filtering Module ---\n",
    "def train_collaborative_filtering(ratings_df, n_components=100, random_state=42):\n",
    "    \"\"\"\n",
    "    Train a collaborative filtering model using TruncatedSVD.\n",
    "    Returns the trained SVD model, user-item matrix, and user/movie mappings.\n",
    "    \"\"\"\n",
    "    # Create user-item matrix\n",
    "    user_item_matrix = ratings_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    \n",
    "    # Map userIds and movieIds to matrix indices\n",
    "    user_ids = user_item_matrix.index\n",
    "    movie_ids = user_item_matrix.columns\n",
    "    \n",
    "    # Initialize and train TruncatedSVD\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=random_state)\n",
    "    user_factors = svd.fit_transform(user_item_matrix)\n",
    "    movie_factors = svd.components_.T\n",
    "    \n",
    "    # Reconstruct predicted ratings matrix\n",
    "    predicted_ratings = np.dot(user_factors, svd.components_)\n",
    "    \n",
    "    return svd, user_item_matrix, user_ids, movie_ids, predicted_ratings\n",
    "\n",
    "def get_collaborative_recommendations(user_id, svd_model, user_item_matrix, user_ids, movie_ids, movies_df, ratings_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Generate collaborative filtering recommendations for a given user.\n",
    "    Returns a DataFrame with movieId, title_clean, predicted_collaborative_score, and genres_str.\n",
    "    \"\"\"\n",
    "    # Check if user exists\n",
    "    if user_id not in user_ids:\n",
    "        print(f\"User {user_id} not found in ratings data.\")\n",
    "        return pd.DataFrame(columns=['movieId', 'title_clean', 'predicted_collaborative_score', 'genres_str'])\n",
    "    \n",
    "    # Get user index\n",
    "    user_idx = user_ids.get_loc(user_id)\n",
    "    \n",
    "    # Get predicted ratings for the user\n",
    "    user_pred_ratings = svd_model[user_idx]\n",
    "    \n",
    "    # Get movies already rated by the user\n",
    "    rated_movie_ids = ratings_df[ratings_df['userId'] == user_id]['movieId'].tolist()\n",
    "    \n",
    "    # Create recommendations list for unrated movies\n",
    "    recommendations = []\n",
    "    for movie_idx, movie_id in enumerate(movie_ids):\n",
    "        if movie_id not in rated_movie_ids:\n",
    "            recommendations.append({\n",
    "                'movieId': movie_id,\n",
    "                'title_clean': movies_df[movies_df['movieId'] == movie_id]['title_clean'].iloc[0],\n",
    "                'predicted_collaborative_score': user_pred_ratings[movie_idx],\n",
    "                'genres_str': movies_df[movies_df['movieId'] == movie_id]['genres_str'].iloc[0]\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame and sort by predicted score\n",
    "    recommendations = pd.DataFrame(recommendations)\n",
    "    recommendations = recommendations.sort_values(by='predicted_collaborative_score', ascending=False).head(top_n)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# --- Content-Based Recommendation Function (Updated) ---\n",
    "def get_content_recommendations_for_user(user_id, ratings_df, movies_df, cosine_sim, indices_map, top_n=10, min_rating_threshold=4.0):\n",
    "    \"\"\"\n",
    "    Generates top N movie recommendations for a given user based on content similarity\n",
    "    to movies they have rated highly.\n",
    "    \"\"\"\n",
    "    # Get movies rated by the user above the threshold\n",
    "    user_ratings = ratings_df[(ratings_df['userId'] == user_id) & (ratings_df['rating'] >= min_rating_threshold)]\n",
    "    \n",
    "    if user_ratings.empty:\n",
    "        print(f\"User {user_id} has no ratings above {min_rating_threshold} or does not exist.\")\n",
    "        return pd.DataFrame(columns=['movieId', 'title_clean', 'predicted_content_score', 'genres_str'])\n",
    "    \n",
    "    # Get the movieIds of movies the user has rated highly\n",
    "    liked_movie_ids = user_ratings['movieId'].tolist()\n",
    "    \n",
    "    # Get the indices in movies_df for these liked movies using movieId\n",
    "    liked_movie_indices = []\n",
    "    for movie_id in liked_movie_ids:\n",
    "        if movie_id in indices_map:\n",
    "            idx = indices_map[movie_id]\n",
    "            if idx < cosine_sim.shape[0]:  # Ensure index is within bounds\n",
    "                liked_movie_indices.append(idx)\n",
    "            else:\n",
    "                print(f\"Warning: Index {idx} for movieId {movie_id} is out of bounds for cosine_sim.\")\n",
    "        else:\n",
    "            print(f\"Warning: movieId {movie_id} not found in indices_map.\")\n",
    "    \n",
    "    if not liked_movie_indices:\n",
    "        print(f\"No valid indices found for liked movies for user {user_id}.\")\n",
    "        return pd.DataFrame(columns=['movieId', 'title_clean', 'predicted_content_score', 'genres_str'])\n",
    "    \n",
    "    # Debugging: Print number of liked movies and indices\n",
    "    print(f\"User {user_id} has {len(liked_movie_indices)} valid liked movie indices: {liked_movie_indices}\")\n",
    "    \n",
    "    # Calculate the average similarity of all other movies to the user's liked movies\n",
    "    try:\n",
    "        user_profile_sim = np.mean(cosine_sim[liked_movie_indices], axis=0)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error computing user profile similarity: {e}\")\n",
    "        return pd.DataFrame(columns=['movieId', 'title_clean', 'predicted_content_score', 'genres_str'])\n",
    "    \n",
    "    # Create a series of similarity scores with movie indices\n",
    "    sim_scores_series = pd.Series(user_profile_sim, index=range(len(movies_df)))\n",
    "    \n",
    "    # Sort movies by these aggregated similarity scores\n",
    "    sorted_sim_scores = sim_scores_series.sort_values(ascending=False)\n",
    "    \n",
    "    # Get movieIds already rated by the user to exclude them\n",
    "    rated_movie_ids = ratings_df[ratings_df['userId'] == user_id]['movieId'].tolist()\n",
    "    \n",
    "    recommendations = []\n",
    "    for movie_idx, score in sorted_sim_scores.items():\n",
    "        if len(recommendations) >= top_n:\n",
    "            break\n",
    "        movie_id_rec = movies_df.iloc[movie_idx]['movieId']\n",
    "        if movie_id_rec not in rated_movie_ids:\n",
    "            recommendations.append({\n",
    "                'movieId': movie_id_rec,\n",
    "                'title_clean': movies_df.iloc[movie_idx]['title_clean'],\n",
    "                'predicted_content_score': score,\n",
    "                'genres_str': movies_df.iloc[movie_idx]['genres_str']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(recommendations)\n",
    "\n",
    "# --- Hybrid Recommendation Engine ---\n",
    "def get_hybrid_recommendations(user_id, svd_model, user_item_matrix, user_ids, movie_ids, ratings_df, movies_df, cosine_sim_content, indices, top_n=10, collab_weight=0.5, content_weight=0.5, min_rating_threshold=4.0):\n",
    "    \"\"\"\n",
    "    Combines content-based and collaborative filtering recommendations using a weighted average.\n",
    "    Returns a DataFrame with hybrid recommendations.\n",
    "    \"\"\"\n",
    "    # Get content-based recommendations\n",
    "    content_recs = get_content_recommendations_for_user(user_id, ratings_df, movies_df, cosine_sim_content, indices, top_n=20, min_rating_threshold=min_rating_threshold)\n",
    "    \n",
    "    # Get collaborative filtering recommendations\n",
    "    collab_recs = get_collaborative_recommendations(user_id, svd_model, user_item_matrix, user_ids, movie_ids, movies_df, ratings_df, top_n=20)\n",
    "    \n",
    "    # Handle cases where one or both recommendation lists are empty\n",
    "    if content_recs.empty and not collab_recs.empty:\n",
    "        print(f\"No content-based recommendations for User {user_id}. Returning collaborative recommendations.\")\n",
    "        return collab_recs.head(top_n)[['movieId', 'title_clean', 'predicted_collaborative_score', 'genres_str']].rename(columns={'predicted_collaborative_score': 'hybrid_score'})\n",
    "    if collab_recs.empty and not content_recs.empty:\n",
    "        print(f\"No collaborative recommendations for User {user_id}. Returning content-based recommendations.\")\n",
    "        return content_recs.head(top_n)[['movieId', 'title_clean', 'predicted_content_score', 'genres_str']].rename(columns={'predicted_content_score': 'hybrid_score'})\n",
    "    if content_recs.empty and collab_recs.empty:\n",
    "        print(f\"No recommendations generated for User {user_id}.\")\n",
    "        return pd.DataFrame(columns=['movieId', 'title_clean', 'hybrid_score', 'genres_str'])\n",
    "    \n",
    "    # Normalize scores to [0,1] for fair combination\n",
    "    scaler = MinMaxScaler()\n",
    "    content_recs['normalized_content_score'] = scaler.fit_transform(content_recs[['predicted_content_score']])\n",
    "    collab_recs['normalized_collab_score'] = scaler.fit_transform(collab_recs[['predicted_collaborative_score']])\n",
    "    \n",
    "    # Merge recommendations on movieId\n",
    "    merged_recs = pd.merge(\n",
    "        content_recs[['movieId', 'title_clean', 'normalized_content_score', 'genres_str']],\n",
    "        collab_recs[['movieId', 'normalized_collab_score']],\n",
    "        on='movieId',\n",
    "        how='outer'\n",
    "    )\n",
    "    \n",
    "    # Fill NaN scores\n",
    "    merged_recs['normalized_content_score'] = merged_recs['normalized_content_score'].fillna(0)\n",
    "    merged_recs['normalized_collab_score'] = merged_recs['normalized_collab_score'].fillna(0)\n",
    "    \n",
    "    # Compute hybrid score\n",
    "    merged_recs['hybrid_score'] = (collab_weight * merged_recs['normalized_collab_score'] + \n",
    "                                   content_weight * merged_recs['normalized_content_score'])\n",
    "    \n",
    "    # Sort by hybrid score and select top N\n",
    "    hybrid_recs = merged_recs.sort_values(by='hybrid_score', ascending=False).head(top_n)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    hybrid_recs = hybrid_recs[['movieId', 'title_clean', 'hybrid_score', 'genres_str']].reset_index(drop=True)\n",
    "    \n",
    "    return hybrid_recs\n",
    "\n",
    "# --- Testing the Implementation ---\n",
    "print(\"\\n--- Training Collaborative Filtering Model ---\")\n",
    "svd_model, user_item_matrix, user_ids, movie_ids, predicted_ratings = train_collaborative_filtering(ratings_df)\n",
    "\n",
    "print(\"\\n--- Testing Collaborative Recommendations for User 1 ---\")\n",
    "collab_recs = get_collaborative_recommendations(1, predicted_ratings, user_item_matrix, user_ids, movie_ids, movies_df, ratings_df, top_n=5)\n",
    "print(collab_recs[['title_clean', 'predicted_collaborative_score', 'genres_str']])\n",
    "\n",
    "print(\"\\n--- Testing Hybrid Recommendations for User 1 ---\")\n",
    "hybrid_recs = get_hybrid_recommendations(1, predicted_ratings, user_item_matrix, user_ids, movie_ids, ratings_df, movies_df, cosine_sim_content, indices, top_n=5)\n",
    "print(hybrid_recs[['title_clean', 'hybrid_score', 'genres_str']])\n",
    "\n",
    "# --- Save Collaborative Model ---\n",
    "try:\n",
    "    os.makedirs('../models/', exist_ok=True)\n",
    "    import joblib\n",
    "    joblib.dump(svd_model, '../models/truncated_svd_model.joblib')\n",
    "    print(\"\\nTruncated SVD model saved to '../models/truncated_svd_model.joblib'\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError saving Truncated SVD model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e9072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
