{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30a840d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial Setup and Data Loading ---\n",
      "Loaded 'cosine_similarity_content.npy' successfully.\n",
      "Cosine similarity matrix shape: (9742, 9742)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib # For non-Surprise model artifacts if any\n",
    "\n",
    "# --- Surprise Library Imports ---\n",
    "from surprise import Dataset, Reader, SVD, SVDpp # SVDpp often gives better results\n",
    "import surprise.dump # For saving/loading Surprise models\n",
    "from surprise.model_selection import GridSearchCV # For hyperparameter tuning\n",
    "# --- End Surprise Library Imports ---\n",
    "\n",
    "print(\"--- Initial Setup and Data Loading ---\")\n",
    "# Define paths\n",
    "DATA_PATH = '../data/'\n",
    "MODELS_PATH = '../models/'\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "# Load datasets\n",
    "movies_df = pd.read_csv(DATA_PATH + 'movies_processed.csv')\n",
    "ratings_df = pd.read_csv(DATA_PATH + 'ratings.csv')\n",
    "\n",
    "# Load content-based similarity matrix\n",
    "try:\n",
    "    cosine_sim_content = np.load(DATA_PATH + 'cosine_similarity_content.npy')\n",
    "    print(\"Loaded 'cosine_similarity_content.npy' successfully.\")\n",
    "    print(f\"Cosine similarity matrix shape: {cosine_sim_content.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'cosine_similarity_content.npy' not found. Ensure it's generated.\")\n",
    "    raise\n",
    "\n",
    "if cosine_sim_content.shape[0] != len(movies_df):\n",
    "    raise ValueError(\"Mismatch between cosine_sim_content and movies_df.\")\n",
    "\n",
    "# Indices map for content-based: movieId to DataFrame row index\n",
    "indices_map_movieId_to_df_idx = pd.Series(movies_df.index, index=movies_df['movieId']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42192cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Collaborative Filtering Module with Surprise ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Collaborative Filtering Module (Surprise)\n",
    "print(\"\\n--- Defining Collaborative Filtering Module with Surprise ---\")\n",
    "\n",
    "def train_collaborative_filtering_surprise(ratings_df_input, algo_choice='SVD', best_params=None, random_state=42):\n",
    "    \"\"\"\n",
    "    Train a collaborative filtering model using Surprise with specified or default parameters.\n",
    "    \"\"\"\n",
    "    print(f\"Training Surprise {algo_choice} model...\")\n",
    "    reader = Reader(rating_scale=(ratings_df_input['rating'].min(), ratings_df_input['rating'].max()))\n",
    "    data = Dataset.load_from_df(ratings_df_input[['userId', 'movieId', 'rating']], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    if best_params is None: # Default parameters if no tuning results provided\n",
    "        best_params = {'n_factors': 100, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.02}\n",
    "        if algo_choice == 'SVDpp': # SVDpp defaults might differ\n",
    "             best_params = {'n_factors': 30, 'n_epochs': 20, 'lr_all': 0.007, 'reg_all': 0.02}\n",
    "\n",
    "\n",
    "    print(f\"Using parameters for {algo_choice}: {best_params}\")\n",
    "    if algo_choice == 'SVDpp':\n",
    "        algo = SVDpp(**best_params, random_state=random_state, verbose=False, cache_ratings=True)\n",
    "    else: # Default to SVD\n",
    "        algo = SVD(**best_params, biased=True, random_state=random_state, verbose=False)\n",
    "    \n",
    "    algo.fit(trainset)\n",
    "    print(\"Surprise model training complete.\")\n",
    "    return algo, trainset\n",
    "\n",
    "def get_collaborative_recommendations_surprise(user_id, surprise_algo, trainset, movies_df_cf, all_ratings_df_for_exclusion, top_n=10):\n",
    "    all_movie_raw_ids = [trainset.to_raw_iid(inner_id) for inner_id in trainset.all_items()]\n",
    "    rated_movie_ids = all_ratings_df_for_exclusion[all_ratings_df_for_exclusion['userId'] == user_id]['movieId'].unique().tolist()\n",
    "    \n",
    "    recommendations = []\n",
    "    try:\n",
    "        _ = trainset.to_inner_uid(user_id) # Check if user is known\n",
    "    except ValueError:\n",
    "        print(f\"User {user_id} not in trainset. CF predictions may be based on global average.\")\n",
    "\n",
    "    for movie_id in all_movie_raw_ids:\n",
    "        if movie_id not in rated_movie_ids:\n",
    "            prediction = surprise_algo.predict(uid=user_id, iid=movie_id)\n",
    "            movie_detail = movies_df_cf[movies_df_cf['movieId'] == movie_id]\n",
    "            if not movie_detail.empty:\n",
    "                recommendations.append({\n",
    "                    'movieId': movie_id,\n",
    "                    'title_clean': movie_detail['title_clean'].iloc[0],\n",
    "                    'predicted_collaborative_score': prediction.est,\n",
    "                    'genres_str': movie_detail.get('genres_str', pd.Series([\"\"])).iloc[0] # Safer get\n",
    "                })\n",
    "    \n",
    "    recs_df = pd.DataFrame(recommendations)\n",
    "    if not recs_df.empty:\n",
    "        recs_df = recs_df.sort_values(by='predicted_collaborative_score', ascending=False).head(top_n)\n",
    "    return recs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c10c8d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hyperparameter Tuning for Surprise CF Model ---\n",
      "Running GridSearchCV for SVD... This will take time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   19.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV complete.\n",
      "Best RMSE score achieved: 0.8635\n",
      "Best parameters for SVD: {'n_factors': 150, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:   22.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Hyperparameter Tuning for Surprise CF\n",
    "print(\"\\n--- Hyperparameter Tuning for Surprise CF Model ---\")\n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD, SVDpp, Dataset, Reader # Ensure SVDpp is imported if you use it\n",
    "\n",
    "reader_tune = Reader(rating_scale=(ratings_df['rating'].min(), ratings_df['rating'].max()))\n",
    "data_tune = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader_tune)\n",
    "\n",
    "# --- CHOOSE YOUR ALGORITHM AND PARAMETER GRID ---\n",
    "CHOSEN_ALGORITHM_FOR_TUNING = SVD # Or SVDpp\n",
    "PARAM_GRID_FOR_TUNING = {         # Adjust based on chosen algorithm\n",
    "    'n_factors': [50, 100, 150],      \n",
    "    'n_epochs': [20, 30], # Increase epochs for potentially better convergence      \n",
    "    'lr_all': [0.005, 0.007, 0.01], \n",
    "    'reg_all': [0.02, 0.04, 0.06]    \n",
    "}\n",
    "# Example for SVDpp (often needs fewer factors):\n",
    "# CHOSEN_ALGORITHM_FOR_TUNING = SVDpp\n",
    "# PARAM_GRID_FOR_TUNING = {\n",
    "#     'n_factors': [20, 30, 40],\n",
    "#     'n_epochs': [20, 30],\n",
    "#     'lr_all': [0.007, 0.01],\n",
    "#     'reg_all': [0.02, 0.04]\n",
    "# }\n",
    "# --- END ALGORITHM CHOICE ---\n",
    "\n",
    "gs = GridSearchCV(CHOSEN_ALGORITHM_FOR_TUNING, PARAM_GRID_FOR_TUNING, measures=['rmse', 'mae'], cv=3, joblib_verbose=5, n_jobs=-1) \n",
    "# Using cv=3, increase if time allows for more robust tuning.\n",
    "\n",
    "print(f\"Running GridSearchCV for {CHOSEN_ALGORITHM_FOR_TUNING.__name__}... This will take time.\")\n",
    "gs.fit(data_tune)\n",
    "print(\"GridSearchCV complete.\")\n",
    "\n",
    "print(f\"Best RMSE score achieved: {gs.best_score['rmse']:.4f}\")\n",
    "best_params_cf = gs.best_params['rmse'] \n",
    "print(f\"Best parameters for {CHOSEN_ALGORITHM_FOR_TUNING.__name__}: {best_params_cf}\")\n",
    "\n",
    "# The rest of your notebook (Cell 4 onwards) will now use this `best_params_cf`\n",
    "# when `train_collaborative_filtering_surprise` is called in Cell 6.\n",
    "# And the CHOSEN_CF_ALGORITHM in Cell 6 should match CHOSEN_ALGORITHM_FOR_TUNING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b3b748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Content-Based Recommendation Module ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Content-Based Recommendation Function (Using your corrected version)\n",
    "print(\"\\n--- Defining Content-Based Recommendation Module ---\")\n",
    "def get_content_recommendations_for_user(user_id, ratings_df_content, movies_df_content, cosine_sim_matrix, \n",
    "                                         local_indices_map_movieId_to_df_idx, top_n=10, min_rating_threshold=4.0):\n",
    "    user_ratings = ratings_df_content[(ratings_df_content['userId'] == user_id) & (ratings_df_content['rating'] >= min_rating_threshold)]\n",
    "    if user_ratings.empty:\n",
    "        return pd.DataFrame(columns=['movieId', 'title_clean', 'predicted_content_score', 'genres_str'])\n",
    "    \n",
    "    liked_movie_ids = user_ratings['movieId'].tolist()\n",
    "    liked_movie_indices_in_cosine_sim = [local_indices_map_movieId_to_df_idx[mid] for mid in liked_movie_ids if mid in local_indices_map_movieId_to_df_idx and 0 <= local_indices_map_movieId_to_df_idx[mid] < cosine_sim_matrix.shape[0]]\n",
    "\n",
    "    if not liked_movie_indices_in_cosine_sim:\n",
    "        return pd.DataFrame(columns=['movieId', 'title_clean', 'predicted_content_score', 'genres_str'])\n",
    "    \n",
    "    try:\n",
    "        user_profile_sim_vector = np.mean(cosine_sim_matrix[liked_movie_indices_in_cosine_sim, :], axis=0)\n",
    "    except (IndexError, ValueError) as e:\n",
    "        print(f\"Error (Content Profile): {e}\"); return pd.DataFrame()\n",
    "    \n",
    "    sim_scores_series = pd.Series(user_profile_sim_vector, index=movies_df_content.index) \n",
    "    sorted_sim_scores = sim_scores_series.sort_values(ascending=False)\n",
    "    \n",
    "    rated_movie_ids_by_user_overall = ratings_df_content[ratings_df_content['userId'] == user_id]['movieId'].unique().tolist()\n",
    "    \n",
    "    recommendations = []\n",
    "    for movie_df_idx, score in sorted_sim_scores.items(): \n",
    "        if len(recommendations) >= top_n: break\n",
    "        movie_info = movies_df_content.loc[movie_df_idx] \n",
    "        movie_id_rec = movie_info['movieId']\n",
    "        if movie_id_rec not in rated_movie_ids_by_user_overall:\n",
    "            genres_value = movie_info.get('genres_str', \"\")\n",
    "            if not isinstance(genres_value, str) or pd.isna(genres_value): genres_value = \"\"\n",
    "            recommendations.append({\n",
    "                'movieId': movie_id_rec, 'title_clean': movie_info['title_clean'],\n",
    "                'predicted_content_score': score, 'genres_str': genres_value\n",
    "            })\n",
    "    return pd.DataFrame(recommendations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "709a7e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Hybrid Recommendation Engine ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Hybrid Recommendation Engine (No major changes to logic, just ensures it uses new CF)\n",
    "print(\"\\n--- Defining Hybrid Recommendation Engine ---\")\n",
    "def get_hybrid_recommendations(user_id, surprise_algo_hybrid, trainset_hybrid, cosine_sim_content_hybrid, \n",
    "                               indices_map_content_hybrid, ratings_df_hybrid, movies_df_hybrid, \n",
    "                               top_n=10, collab_weight=0.5, content_weight=0.5, \n",
    "                               min_rating_threshold_content_profile=4.0):\n",
    "    num_initial_recs = top_n * 3\n",
    "    content_recs = get_content_recommendations_for_user(user_id, ratings_df_hybrid, movies_df_hybrid, cosine_sim_content_hybrid, indices_map_content_hybrid, top_n=num_initial_recs, min_rating_threshold=min_rating_threshold_content_profile)\n",
    "    collab_recs = get_collaborative_recommendations_surprise(user_id, surprise_algo_hybrid, trainset_hybrid, movies_df_hybrid, ratings_df_hybrid, top_n=num_initial_recs)\n",
    "\n",
    "    # ... (rest of the hybrid logic remains largely the same as your last version) ...\n",
    "    # Ensure 'normalized_score' is used consistently from both, and merging logic is sound.\n",
    "    no_content = content_recs.empty\n",
    "    no_collab = collab_recs.empty\n",
    "\n",
    "    if no_content and no_collab: return pd.DataFrame(columns=['movieId', 'title_clean', 'hybrid_score', 'genres_str'])\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    if not no_content and 'predicted_content_score' in content_recs.columns and content_recs['predicted_content_score'].notna().any():\n",
    "        if content_recs['predicted_content_score'].nunique() > 1: content_recs['normalized_score'] = scaler.fit_transform(content_recs[['predicted_content_score']])\n",
    "        elif len(content_recs) > 0: content_recs['normalized_score'] = 0.5 if content_recs['predicted_content_score'].iloc[0] != 0 else 0.0\n",
    "        else: content_recs['normalized_score'] = 0.0; no_content = True\n",
    "    else:\n",
    "        if 'normalized_score' not in content_recs: content_recs['normalized_score'] = pd.NA\n",
    "        no_content = True\n",
    "        \n",
    "    if not no_collab and 'predicted_collaborative_score' in collab_recs.columns and collab_recs['predicted_collaborative_score'].notna().any():\n",
    "        if collab_recs['predicted_collaborative_score'].nunique() > 1: collab_recs['normalized_score'] = scaler.fit_transform(collab_recs[['predicted_collaborative_score']])\n",
    "        elif len(collab_recs) > 0: collab_recs['normalized_score'] = 0.5 if collab_recs['predicted_collaborative_score'].iloc[0] !=0 else 0.0\n",
    "        else: collab_recs['normalized_score'] = 0.0; no_collab = True\n",
    "    else:\n",
    "        if 'normalized_score' not in collab_recs: collab_recs['normalized_score'] = pd.NA\n",
    "        no_collab = True\n",
    "\n",
    "    if no_content and not no_collab: return collab_recs.head(top_n).rename(columns={'predicted_collaborative_score': 'hybrid_score', 'normalized_score': 'hybrid_norm_score_debug'})[['movieId', 'title_clean', 'hybrid_score', 'genres_str']] # Adjust for clarity\n",
    "    if no_collab and not no_content: return content_recs.head(top_n).rename(columns={'predicted_content_score': 'hybrid_score', 'normalized_score': 'hybrid_norm_score_debug'})[['movieId', 'title_clean', 'hybrid_score', 'genres_str']]\n",
    "    if no_collab and no_content: return pd.DataFrame(columns=['movieId', 'title_clean', 'hybrid_score', 'genres_str'])\n",
    "\n",
    "    merged_recs = pd.merge(\n",
    "        content_recs[['movieId', 'title_clean', 'genres_str', 'normalized_score']],\n",
    "        collab_recs[['movieId', 'normalized_score']],\n",
    "        on='movieId', how='outer', suffixes=('_content', '_collab')\n",
    "    )\n",
    "    merged_recs['normalized_score_content'] = merged_recs['normalized_score_content'].fillna(0)\n",
    "    merged_recs['normalized_score_collab'] = merged_recs['normalized_score_collab'].fillna(0)\n",
    "    \n",
    "    if 'title_clean_content' in merged_recs.columns: # From suffix\n",
    "        merged_recs['title_clean'] = merged_recs['title_clean_content']\n",
    "        merged_recs['genres_str'] = merged_recs['genres_str_content']\n",
    "        merged_recs.drop(columns=['title_clean_content', 'genres_str_content'], inplace=True, errors='ignore')\n",
    "\n",
    "    merged_recs.dropna(subset=['title_clean'], inplace=True)\n",
    "    merged_recs['hybrid_score'] = (collab_weight * merged_recs['normalized_score_collab'] + content_weight * merged_recs['normalized_score_content'])\n",
    "    \n",
    "    final_recs = merged_recs.sort_values(by='hybrid_score', ascending=False).drop_duplicates(subset=['movieId'], keep='first').head(top_n)\n",
    "    return final_recs[['movieId', 'title_clean', 'hybrid_score', 'genres_str']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95e57b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Training Main Collaborative Filtering Model (Surprise SVD/SVDpp with best_params_cf) ---\n",
      "Training Surprise SVD model...\n",
      "Using parameters for SVD: {'n_factors': 150, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.06}\n",
      "Surprise model training complete.\n",
      "\n",
      "--- Testing Collaborative Recommendations for User 1 (Tuned SVD) ---\n",
      "      movieId                                        title_clean  \\\n",
      "0         318                          Shawshank Redemption, The   \n",
      "4029     1178                                     Paths of Glory   \n",
      "2886   158966                                  Captain Fantastic   \n",
      "2984    42632  Lady Vengeance (Sympathy for Lady Vengeance) (...   \n",
      "3168    51709                                Host, The (Gwoemul)   \n",
      "\n",
      "      predicted_collaborative_score                           genres_str  \n",
      "0                               5.0                          Crime Drama  \n",
      "4029                            5.0                            Drama War  \n",
      "2886                            5.0                                Drama  \n",
      "2984                            5.0         Crime Drama Mystery Thriller  \n",
      "3168                            5.0  Comedy Drama Horror Sci-Fi Thriller  \n",
      "\n",
      "--- Testing Content-Based Recommendations for User 1 ---\n",
      "   movieId      title_clean  predicted_content_score  \\\n",
      "0     5657        Flashback                 0.266021   \n",
      "1     4956   Stunt Man, The                 0.255555   \n",
      "2    87529    Your Highness                 0.253022   \n",
      "3   157865  Ratchet & Clank                 0.247699   \n",
      "4    27036           Merlin                 0.242872   \n",
      "\n",
      "                                          genres_str  \n",
      "0                Action Adventure Comedy Crime Drama  \n",
      "1     Action Adventure Comedy Drama Romance Thriller  \n",
      "2                    Action Adventure Comedy Fantasy  \n",
      "3  Action Adventure Animation Children Comedy Sci-Fi  \n",
      "4             Action Adventure Drama Fantasy Romance  \n",
      "\n",
      "--- Testing Hybrid Recommendations for User 1 (Tuned SVD) ---\n",
      "   movieId      title_clean  hybrid_score  \\\n",
      "0     5657        Flashback      0.200000   \n",
      "1     4956   Stunt Man, The      0.124073   \n",
      "2    87529    Your Highness      0.105691   \n",
      "3   157865  Ratchet & Clank      0.067079   \n",
      "4    27036           Merlin      0.032063   \n",
      "\n",
      "                                          genres_str  \n",
      "0                Action Adventure Comedy Crime Drama  \n",
      "1     Action Adventure Comedy Drama Romance Thriller  \n",
      "2                    Action Adventure Comedy Fantasy  \n",
      "3  Action Adventure Animation Children Comedy Sci-Fi  \n",
      "4             Action Adventure Drama Fantasy Romance  \n",
      "\n",
      "--- Saving Tuned Collaborative Model (Surprise) ---\n",
      "Surprise SVD model saved to '../models/surprise_svd_model_tuned.joblib'\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Training Main CF Model and Testing\n",
    "print(\"\\n\\n--- Training Main Collaborative Filtering Model (Surprise SVD/SVDpp with best_params_cf) ---\")\n",
    "# CHOOSE 'SVD' or 'SVDpp' based on your tuning results and preference\n",
    "CHOSEN_CF_ALGORITHM = 'SVD' # Or 'SVDpp'\n",
    "surprise_cf_algo, surprise_trainset = train_collaborative_filtering_surprise(\n",
    "    ratings_df, \n",
    "    algo_choice=CHOSEN_CF_ALGORITHM,\n",
    "    best_params=best_params_cf # Use the tuned (or placeholder) parameters\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Testing Collaborative Recommendations for User 1 (Tuned {CHOSEN_CF_ALGORITHM}) ---\")\n",
    "collab_recs_surprise = get_collaborative_recommendations_surprise(1, surprise_cf_algo, surprise_trainset, movies_df, ratings_df, top_n=5)\n",
    "if not collab_recs_surprise.empty: print(collab_recs_surprise)\n",
    "else: print(\"No collab recs.\")\n",
    "\n",
    "print(\"\\n--- Testing Content-Based Recommendations for User 1 ---\")\n",
    "content_recs_user1 = get_content_recommendations_for_user(1, ratings_df, movies_df, cosine_sim_content, indices_map_movieId_to_df_idx, top_n=5)\n",
    "if not content_recs_user1.empty: print(content_recs_user1)\n",
    "else: print(\"No content recs.\")\n",
    "\n",
    "print(f\"\\n--- Testing Hybrid Recommendations for User 1 (Tuned {CHOSEN_CF_ALGORITHM}) ---\")\n",
    "hybrid_recs_user1 = get_hybrid_recommendations(\n",
    "    user_id=1, surprise_algo_hybrid=surprise_cf_algo, trainset_hybrid=surprise_trainset,\n",
    "    cosine_sim_content_hybrid=cosine_sim_content, indices_map_content_hybrid=indices_map_movieId_to_df_idx,\n",
    "    ratings_df_hybrid=ratings_df, movies_df_hybrid=movies_df, top_n=5,\n",
    "    collab_weight=0.8, content_weight=0.2 # Example weights, tune these too!\n",
    ")\n",
    "if not hybrid_recs_user1.empty: print(hybrid_recs_user1)\n",
    "else: print(\"No hybrid recs.\")\n",
    "\n",
    "# Cell 7: Save Collaborative Model (Surprise)\n",
    "print(\"\\n--- Saving Tuned Collaborative Model (Surprise) ---\")\n",
    "surprise_model_filename = f\"surprise_{CHOSEN_CF_ALGORITHM.lower()}_model_tuned.joblib\"\n",
    "surprise_model_path = os.path.join(MODELS_PATH, surprise_model_filename)\n",
    "try:\n",
    "    surprise.dump.dump(surprise_model_path, algo=surprise_cf_algo)\n",
    "    print(f\"Surprise {CHOSEN_CF_ALGORITHM} model saved to '{surprise_model_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving Surprise model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74319c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
